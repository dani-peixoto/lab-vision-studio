# Reconhecimento Facial e transforma√ß√£o de imagens em Dados no Azure ML

### Documenta√ß√£o criada para mostrar como realizar a detec√ß√£o de rostos, extra√ß√£o de textos de imagens, gera√ß√£o de legenda, cria√ß√£o de tags e detec√ß√£o de objetos utilizando o Azure Vision Studio.

> [!Important]
> Num navegador web, navegue at√© **Vision Studio** em **https://portal.vision.cognitive.azure.com** para explorar todas as op√ß√µes.

## Detecte rostos no Vision Studio

1. Na p√°gina inicial **Getting started with Vision**, selecione a guia **Face** e, em seguida, selecione o bloco **Detect Faces in an image**.
   
1. No subt√≠tulo **Try It Out**, reconhe√ßa a pol√≠tica de uso de recursos lendo e marcando a caixa.

1. Selecione cada uma das imagens de amostra e observe os dados de detec√ß√£o facial retornados.

![image](https://github.com/dani-peixoto/lab-vision-studio/assets/3649843/11a7a65d-b5ed-4a5d-b0f3-8282568a0e48)

## Extraia texto de imagens no Vision Studio

1. Na p√°gina inicial **Getting started with Vision**, selecione **Optical character recognition** e, em seguida, o bloco **Extract text from images**.

1. No subt√≠tulo **Try It Out**, reconhe√ßa a pol√≠tica de uso de recursos lendo e marcando a caixa.

1. Selecione cada uma das imagens de amostra e revise o que √© retornado.
   
   - Nos atributos detectados , qualquer texto encontrado na imagem √© organizado em uma estrutura hier√°rquica de regi√µes, linhas e palavras.
   - Na imagem, a localiza√ß√£o do texto √© indicada por uma caixa delimitadora, conforme mostrado aqui:
  
![image](https://github.com/dani-peixoto/lab-vision-studio/assets/3649843/79a3d8ad-f3ad-4717-9803-8e0d0e1206fd)

## Gerar legendas para uma imagem

üí° Vejamos a funcionalidade de legenda de imagens do Azure AI Vision. As legendas das imagens est√£o dispon√≠veis por meio dos recursos **Caption** e **Denses captions**.

1. Na p√°gina inicial **Getting started with Vision**, selecione **Image analysis** e, em seguida, o bloco **Add captions to images**.
   
1. No subt√≠tulo **Try It Out**, reconhe√ßa a pol√≠tica de uso de recursos lendo e marcando a caixa.
   
1. Observe o texto da legenda gerado, vis√≠vel no painel Atributos detectados √† direita da imagem.

1. A funcionalidade Caption fornece uma √∫nica frase em ingl√™s leg√≠vel que descreve o conte√∫do da imagem.

![image](https://github.com/dani-peixoto/lab-vision-studio/assets/3649843/549f3891-b77e-4488-b47a-b4f307fb9a6a)

5. Em seguida, use a mesma imagem para realizar legendas densas. Retorne √† p√°gina inicial do Vision Studio e, como fez antes, selecione a guia **Image analysis** e, em seguida, selecione o bloco **dense captions**.

![image](https://github.com/dani-peixoto/lab-vision-studio/assets/3649843/b24b5c5a-6f5c-471b-b343-96c44dd81e5d)

üì£ O recurso Dense Captions difere do recurso Caption porque fornece diversas legendas leg√≠veis para uma imagem, uma descrevendo o conte√∫do da imagem e outras, cada uma cobrindo os objetos essenciais detectados na imagem. Cada objeto detectado inclui uma caixa delimitadora, que define as coordenadas dos pixels na imagem associada ao objeto.

## Marcando imagens

üí° O pr√≥ximo recurso que voc√™ experimentar√° √© a funcionalidade Extrair Tags. Extrair tags √© baseado em milhares de objetos reconhec√≠veis, incluindo seres vivos, cen√°rios e a√ß√µes.

1. Na p√°gina inicial **Getting started with Vision**, selecione **Extract common tags from images** e, em seguida, o bloco **Image analysis tab**.

1. Em Escolha o modelo que deseja experimentar, deixe selecionado **Prebuilt product vs. gap model**. Em Escolha seu idioma, selecione English ou um idioma de sua prefer√™ncia.

1. Selecione cada uma das imagens de amostra e observe as tags retornadas.

![image](https://github.com/dani-peixoto/lab-vision-studio/assets/3649843/42f1f39b-bca8-4be6-adc6-bb901af448ad)

## Detec√ß√£o de objetos

üí° A detec√ß√£o de objetos detecta e extrai caixas delimitadoras com base em milhares de objetos e seres vivos reconhec√≠veis.

1. Na p√°gina inicial **Getting started with Vision**, selecione **Detect common objects in images** e, em seguida, o bloco **Image analysis tab**.

1. Em Escolha o modelo que deseja experimentar, deixe selecionado **Prebuilt product vs. gap model**.

1. Na caixa Atributos detectados , observe a lista de objetos detectados e suas pontua√ß√µes de confian√ßa.

1. Passe o cursor do mouse sobre os objetos na lista Atributos detectados para destacar a caixa delimitadora do objeto na imagem.

1. Mova o controle deslizante Valor limite at√© que um valor de 70 seja exibido √† direita do controle deslizante. Observe o que acontece com os objetos da lista. O controle deslizante de limite especifica que somente objetos identificados com uma pontua√ß√£o de confian√ßa ou probabilidade maior que o limite devem ser exibidos.

![image](https://github.com/dani-peixoto/lab-vision-studio/assets/3649843/f01d81a5-dedd-423f-ab21-021e2d686aea)
